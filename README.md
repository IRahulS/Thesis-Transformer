# Multimodal Hyperspectral Unmixing: Insights from Attention Networks

[Zhu Han](https://www.researchgate.net/profile/Zhu-Han-2), [Danfeng Hong](https://sites.google.com/view/danfeng-hong), [Lianru Gao](https://scholar.google.com/citations?hl=en&user=f6OnhtcAAAAJ), [Jing Yao](https://scholar.google.com/citations?user=1SHd5ygAAAAJ&hl=en), [Bing Zhang](http://english.radi.cas.cn/Education/PhDS/201401/t20140109_115415.html), [Jocelyn Chanussot](http://jocelyn-chanussot.net/)

___________

The code in this toolbox implements the "Multimodal Hyperspectral Unmixing: Insights from Attention Networks". More specifically, it is detailed as follow.

![alt text](./MUNet.PNG)

Citation
---------------------

**Please kindly cite the papers if this code is useful and helpful for your research.**

Zhu Han, Danfeng Hong, Lianru Gao, Jing Yao, Bing Zhang, Jocelyn Chanussot. Multimodal Hyperspectral Unmixing: Insights from Attention Networks, IEEE Transactions on Geoscience and Remote Sensing (TGRS), 2022, DOI: 10.1109/TGRS.2022.3155794.

    @article{han2022munet,
      title={Multimodal hyperspectral unmixing: insights from attention networks},
      author={Han, Zhu and Hong, Danfeng and Gao, Lianru and Yao, Jing and Zhang, Bing and Chanussot, Jocelyn},
      journal={IEEE Trans. Geosci. Remote Sens.},
      note = {DOI: 10.1109/TGRS.2022.3155794},
      year={2022}  
    }
